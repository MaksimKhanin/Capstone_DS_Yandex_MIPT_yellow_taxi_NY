{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Неделя 5\n\n## Постановка задачи\n\n### Построить прогноз на 6 часов вперед для всех концов истории. Нужно построить 6 независимых регрессионных моделей на каждый T+1\n\n- Для каждой из шести задач прогнозирования сформируйте выборки. Возможные признаки:\n\n  + идентификатор географической зоны — категориальный\n  + год, месяц, день месяца, день недели, час — эти признаки можно пробовать брать и категориальными, и непрерывными, можно даже и так, и так\n  + синусы, косинусы и тренды, которые вы использовали внутри регрессионной компоненты ARIMA\n  + значения прогнозов ARIMA\n  + количество поездок из рассматриваемого района в моменты времени (аналог компоненты AR)\n  + количество поездок из рассматриваемого района в моменты времени (аналог сезонной компоненты AR, суточной)\n  + суммарное количество поездок из рассматриваемого района за предшествующие полдня, сутки, неделю, месяц\n  \n- Разбейте каждую из шести выборок на три части:\n\n  + обучающая, на которой будут настраиваться параметры моделей — всё до апреля 2016\n  + тестовая, на которой вы будете подбирать значения гиперпараметров — май 2016\n  + итоговая, которая не будет использоваться при настройке моделей вообще — июнь 2016\n  \n- Выберите вашу любимую регрессионную модель и настройте её на каждом из шести наборов данных, подбирая гиперпараметры на мае 2016. Желательно, чтобы модель:\n\n  + допускала попарные взаимодействия между признаками\n  + была устойчивой к избыточному количеству признаков (например, использовала регуляризаторы)\n  \n- Выбранными моделями постройте для каждой географической зоны и каждого конца истории от 2016.04.30 23:00 до 2016.05.31 17:00 прогнозы на 6 часов вперёд; посчитайте в ноутбуке ошибку прогноза по ранее указанному функционалу:\n\n- Убедитесь, что ошибка полученных прогнозов, рассчитанная согласно функционалу, определённому на прошлой неделе, уменьшилась по сравнению с той, которую вы получили методом индивидуального применения моделей ARIMA. Если этого не произошло, попробуйте улучшить ваши модели.\n\n- Итоговыми моделями постройте прогнозы для каждого конца истории от 2016.05.31 23:00 до 2016.06.30 17:00 и запишите все результаты в один файл в формате geoID, histEndDay, histEndHour, step, y. Здесь geoID — идентификатор зоны, histEndDay — день конца истории в формате id,y, где столбец id состоит из склеенных через подчёркивание идентификатора географической зоны, даты конца истории, часа конца истории и номера отсчёта, на который делается предсказание (1-6); столбец y — ваш прогноз.\n\n- Загрузите полученный файл на kaggle: https://inclass.kaggle.com/c/yellowtaxi. Добавьте в ноутбук ссылку на сабмишн.\n\n- Загрузите ноутбук в форму."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import os\n\n%matplotlib inline\nimport matplotlib.pylab as plt\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm_notebook as tqdm\n\nfrom sklearn.ensemble import RandomForestRegressor\n\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n\npd.set_option(\"display.max_columns\", 500)",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/home/nbuser/anaconda3_420/lib/python3.5/site-packages/matplotlib/font_manager.py:232: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n  'Matplotlib is building the font cache using fc-list. '\n/home/nbuser/anaconda3_420/lib/python3.5/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n  from numpy.core.umath_tests import inner1d\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Загружаем данные. Отбрасываем нерассматриваниые регионы\ndf = pd.read_csv('taxi_agg.csv', index_col=0)\n# регионы отобрытнные на второй неделе (среднее к-во поездок в мае > 5)\nregions = pd.read_csv('data_week2.csv', index_col=0).index \ndf = df[df['bin_num'].isin(list(regions))]\ndf.index = pd.to_datetime(df.index)\ndf = df.set_index('Pickup_Hour')\ndf = df.pivot_table(values='trip_cnt', index=df.index, columns='bin_num', aggfunc='first')\ndf = df.fillna(0)",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def create_fourier_fet(df, Kn):\n    K = range(1, Kn+1)\n    for sample_ks in K:\n        sin = \"sin_K_\" + str(sample_ks)\n        cos = \"cos_K_\" + str(sample_ks)\n        df[sin] = np.sin(2*np.pi*sample_ks*np.arange(0, len(df))/168)\n        df[cos] = np.cos(2*np.pi*sample_ks*np.arange(0, len(df))/168)\n    return df\n\ndef extract_weekday(df):\n    \n    names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n    df.index = pd.to_datetime(df.index)\n    df = df.join(pd.get_dummies(df.index.get_level_values(0).weekday_name) \\\n                .set_index(df.index).reindex(columns=names))\n    \n    return df\n\ndef extract_hour(df):\n    \n    df.index = pd.to_datetime(df.index)\n    df = df.join(pd.get_dummies(df.index.get_level_values(0).hour, prefix = 'hour') \\\n                 .set_index(df.index))\n    return df\n\ndef extract_month(df):\n    \n    df.index = pd.to_datetime(df.index)\n    df = df.join(pd.get_dummies(df.index.get_level_values(0).month, prefix = 'month') \\\n                 .set_index(df.index))\n    return df\n\ndef extract_ar(df, reg, per, step = 1):\n    new_df = pd.DataFrame(index = df.index)\n    for i in range(0, per):\n        new_column = 'ar_' + str(i) + '_' + str(step)\n        new_series = df[reg].shift(i*step)\n        new_df.loc[:, new_column] = new_series\n    return new_df\n\ndef extract_sum(df, reg, per):\n    new_df = pd.DataFrame(index = df.index)\n    new_column = 'sum_' + str(per)\n    new_series = df[reg].rolling(min_periods=per, window=per).sum()\n    new_df.loc[:, new_column] = new_series\n    return new_df\n\ndef extract_mean(df, reg, per):\n    new_df = pd.DataFrame(index = df.index)\n    new_column = 'mean_' + str(per)\n    new_series =  df[reg].rolling(min_periods=per, window=per).mean()\n    new_df.loc[:, new_column] = new_series\n    return new_df",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#extract universal features \ndf_reg = pd.DataFrame(index = df.index)\ndf_reg = create_fourier_fet(df_reg, 15) #Фурье\ndf_reg = extract_weekday(df_reg) #Недели\ndf_reg = extract_hour(df_reg) #Часы\ndf_reg = extract_month(df_reg) #Месяцы",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "Xy = pd.DataFrame()\nfor each_region in tqdm(regions):\n    \n    df_reg['region'] = each_region\n    \n    #df for variable features\n    df_prel = pd.DataFrame(index = df.index)\n    # количество поездок из рассматриваемого района в моменты времени\n    df_prel = df_prel.join(extract_ar(df, each_region, 24, step = 1)) # 24 часа с шагом 1 час\n    df_prel = df_prel.join(extract_ar(df, each_region, 6, step = 24)) # шаг три дня (сезонность)\n    \n    df_prel = df_prel.join(extract_sum(df, each_region, 6)) #cумма за последние 6 часов\n    df_prel = df_prel.join(extract_sum(df, each_region, 12)) #cумма за последние 12 часов\n    df_prel = df_prel.join(extract_sum(df, each_region, 24)) #cумма за последние 24 часа\n    df_prel = df_prel.join(extract_sum(df, each_region, 168)) #cумма за последнюю неделю\n    \n    df_prel = df_prel.join(extract_mean(df, each_region, 6)) #среднее за последние 6 часов\n    df_prel = df_prel.join(extract_mean(df, each_region, 12)) #среднее за последние 12 часов\n    df_prel = df_prel.join(extract_mean(df, each_region, 24)) #среднее за последние 24 часа\n    df_prel = df_prel.join(extract_mean(df, each_region, 168)) #среднее за последнюю неделю\n    \n    df_prel['snow 23-01-2016'] = 0\n    df_prel.loc['2016-01-23':'2016-01-24', 'snow 23-01-2016'] = 1\n    \n    df_prel = df_prel.join(df_reg)\n    df_prel['region'] = each_region\n    # true values 6 hours ahead\n    for i in range(1, 7):\n        df_prel['y'+str(i)] = df[each_region].shift(-i) \n    \n    \n    Xy = Xy.append(df_prel, ignore_index = False)",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/home/nbuser/anaconda3_420/lib/python3.5/site-packages/ipykernel/__main__.py:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\nPlease use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n  from ipykernel import kernelapp as app\n",
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aebe70d42aa64eddb1beb3a5210a6949",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": "HBox(children=(FloatProgress(value=0.0, max=102.0), HTML(value='')))"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": "\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Делим выборку\n#обучающая, на которой будут настраиваться параметры моделей — всё до апреля 2016\n#тестовая, на которой вы будете подбирать значения гиперпараметров — май 2016\n#итоговая, которая не будет использоваться при настройке моделей вообще — июнь 2016\nXy.dropna(axis = 0, inplace = True)\ny_train = Xy.loc[:'2016-04-30 23:00:00', Xy.columns[-7:]]\ny_test = Xy.loc['2016-05-01 00:00:00' : '2016-05-31 23:00:00', Xy.columns[-7:]]\ny_fin = Xy.loc['2016-06-01 00:00:00' :, Xy.columns[-7:]]\n\nX_train = Xy.loc[:'2016-04-30 23:00:00', Xy.columns[:-7]]\nX_test = Xy.loc['2016-05-01 00:00:00' : '2016-05-31 23:00:00', Xy.columns[:-7]]\nX_fin = Xy.loc['2016-06-01 00:00:00' :, Xy.columns[:-7]]",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Choosing n_estimators\nfile_r = 'week5_estimators.txt'\nif os.path.exists(file_r) == False:\n    with open(file_r, 'w') as f:\n        f.write('l_estimators, r_sq, mae\\n')\n\nl_estimators = [10, 25, 50, 75, 100, 125, 150, 300, 500]\nr_sq = []\nmae = []\n\nfor each_est in tqdm(l_estimators):\n    RF = RandomForestRegressor(n_estimators = each_est, random_state = 0, n_jobs = -1)\n    RF.fit(X_train, y_train['y1'])\n    y_hat = RF.predict(X_test)\n    \n    mae.append(mean_absolute_error(y_test['y1'], y_hat))\n    r_sq.append(r2_score(y_test['y1'], y_hat))\n    \n    with open('week5_estimators.txt', 'a') as f:\n        f.write(str(each_est) + ',' + str(r_sq) + ',' + str(mae) + '\\n')",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/home/nbuser/anaconda3_420/lib/python3.5/site-packages/ipykernel/__main__.py:11: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\nPlease use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3987b4cdf9664150976d8935f93fb58f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Обучаем линейную регрессию\nmodel_ens = {}\nfor each_hour in tqdm(range(1, 7)):\n    model_nm = 'model_rf_{}'.format(str(each_hour))\n    y_hour = 'y{}'.format(str(each_hour))\n    model_ens[model_nm] = RandomForestRegressor(random_state = 0, n_jobs = -1)\n    model_ens[model_nm].fit(X_train, y_train[y_hour])",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/home/nbuser/anaconda3_420/lib/python3.5/site-packages/ipykernel/__main__.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\nPlease use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n  app.launch_new_instance()\n",
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "32e7fafddb104c07a272de0f3f349ea1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": "\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "y_hat_1 = model_ens['model_ln_reg_1'].predict(X_test)\ny_hat_2 = model_ens['model_ln_reg_2'].predict(X_test)\ny_hat_3 = model_ens['model_ln_reg_3'].predict(X_test)\ny_hat_4 = model_ens['model_ln_reg_4'].predict(X_test)\ny_hat_5 = model_ens['model_ln_reg_5'].predict(X_test)\ny_hat_6 = model_ens['model_ln_reg_6'].predict(X_test)",
      "execution_count": 19,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(sum(abs(y_test['y1'] - y_hat_1))/len(y_hat_1))\nprint(sum(abs(y_test['y2'] - y_hat_2))/len(y_hat_2))\nprint(sum(abs(y_test['y3'] - y_hat_3))/len(y_hat_3))\nprint(sum(abs(y_test['y4'] - y_hat_4))/len(y_hat_4))\nprint(sum(abs(y_test['y5'] - y_hat_5))/len(y_hat_5))\nprint(sum(abs(y_test['y6'] - y_hat_6))/len(y_hat_6))",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": "16.01815302344706\n18.582298094063308\n19.397161661867482\n19.918985328397476\n20.28750034279499\n20.42389140271537\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "(sum(abs(y_test['y1'] - y_hat_1)) + sum(abs(y_test['y2'] - y_hat_2)) + \n    sum(abs(y_test['y3'] - y_hat_3)) + sum(abs(y_test['y4'] - y_hat_4)) + \n    sum(abs(y_test['y5'] - y_hat_5)) + sum(abs(y_test['y6'] - y_hat_6))) / (len(y_hat_1)*6)",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 29,
          "data": {
            "text/plain": "19.104664975547614"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "df_reg.columns.append(df.columns)",
      "execution_count": 8,
      "outputs": [
        {
          "data": {
            "text/plain": "Int64Index([1075, 1076, 1077, 1125, 1126, 1127, 1128, 1129, 1130, 1131,\n            ...\n            1630, 1684, 1733, 1734, 1783, 2068, 2069, 2118, 2119, 2168],\n           dtype='int64', length=102)"
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "file_extension": ".py",
      "version": "3.5.4",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}